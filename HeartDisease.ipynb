{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"RDZru6F7hSy2","collapsed":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from xgboost import XGBClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import LabelEncoder\n","from matplotlib import pyplot as plt\n","from sklearn import metrics\n","\n","# load data\n","data = pd.read_csv('dataset.csv')\n","\n","# split data into X and y\n","\n","data.info()\n","enc=LabelEncoder()\n","for x in data.columns:\n","    if data[x].dtype=='object':\n","        data[x]=enc.fit_transform(data[x])\n","data.info()\n","\n","y=data['HeartDisease']\n","\n","X=data.drop(['HeartDisease'],axis=1)\n","\n","# split data into train and test sets\n","seed = 7\n","test_size = 0.1\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed, shuffle = True, stratify = y)\n","\n","# fit model to training data\n","\n","# for an imbalanced binary classification dataset, the negative class refers to the majority class (class 0) and the positive class refers to the minority class (class 1)\n","\n","# выбранная модель\n","model = XGBClassifier(scale_pos_weight=10.68, n_estimators=400, learning_rate=0.15, max_depth=10, objective='binary:logistic', booster='gbtree')\n","\n","# printing model parameters\n","print(model)\n","\n","print(\"Fitting:\")\n","eval_set = [(X_train, y_train), (X_test, y_test)]\n","model.fit(X_train, y_train, eval_metric=[\"error\", \"logloss\"], eval_set=eval_set, verbose=False)\n","\n","print(model)\n","\n","# make predictions for test data\n","print(\"Predicting:\")\n","y_pred = model.predict(X_test)\n","predictions = [round(value) for value in y_pred]\n","\n","# evaluate predictions\n","accuracy = accuracy_score(y_test, predictions)\n","print(\"Accuracy: %.2f%%\" %(accuracy * 100.0))\n","\n","# retrieve performance metrics\n","results = model.evals_result()\n","epochs = len(results['validation_0']['error'])\n","x_axis = range(0, epochs)\n","\n","# plot log loss\n","fig, ax = plt.subplots()\n","ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n","ax.plot(x_axis, results['validation_1']['logloss'], label='Test')\n","ax.legend()\n","plt.ylabel('Log Loss')\n","plt.title('XGBoost Log Loss')\n","plt.show()\n","\n","# plot classification error\n","fig, ax = plt.subplots()\n","ax.plot(x_axis, results['validation_0']['error'], label='Train')\n","ax.plot(x_axis, results['validation_1']['error'], label='Test')\n","ax.legend()\n","plt.ylabel('Classification Error')\n","plt.title('XGBoost Classification Error')\n","plt.show()\n","\n","# measuring accuracy on testing data\n","print(\"\\nClassification report for prediction:\")\n","print(metrics.classification_report(y_test, y_pred))\n","print(\"\\nConfusion matrix for prediction:\")\n","print(metrics.confusion_matrix(y_test, y_pred))\n","\n","index=['BMI','Smoking','AlcoholDrinking','Stroke','PhysicalHealth',\n","'MentalHealth','DiffWalking','Gender','AgeCategory','Race','Diabetic',\n","'PhysicalActivity','GenHealth','SleepTime','Asthma','KidneyDisease','SkinCancer']\n","\n","feature_importances = pd.Series(model.feature_importances_, index=index)\n","plt.bar(range(len(feature_importances)), feature_importances)\n","plt.xlabel('Features')\n","plt.ylabel('Significance, %')\n","plt.title('XGBoost Feature Importance')\n","plt.show()\n","\n","print(\"\\nFeature significance\")\n","for i in range(len(feature_importances)):\n","    print(index[i],\":\", feature_importances[i])"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNOgkRM3tWIgnwUpiCfb7IK"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}